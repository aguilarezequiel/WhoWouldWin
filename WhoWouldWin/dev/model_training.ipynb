{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo - WhoWouldWin Argumentative Generator\n",
    "\n",
    "Este notebook entrena un modelo T5 para generar respuestas argumentativas a debates hipotéticos.\n",
    "\n",
    "**Objetivo**: Entrenar modelo seq2seq desde modelo preentrenado con recursos limitados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: cuda\n",
      "GPU: NVIDIA GeForce RTX 5090\n",
      "Memoria GPU: 34.19 GB\n"
     ]
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "from transformers import T5Tokenizer, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de reproducibilidad\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Verificar disponibilidad de GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Dispositivo: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datasets Preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración del dataset:\n",
      "tokenizer_name: t5-small\n",
      "max_input_length: 10000\n",
      "max_output_length: 10000\n",
      "batch_size: 4\n",
      "train_size: 7580\n",
      "val_size: 947\n",
      "test_size: 948\n",
      "\n",
      "Datasets cargados:\n",
      "Train: 7580 ejemplos\n",
      "Val: 947 ejemplos\n",
      "Test: 948 ejemplos\n"
     ]
    }
   ],
   "source": [
    "# Cargar configuración del dataset\n",
    "with open('data/dataset_config.pkl', 'rb') as f:\n",
    "    dataset_config = pickle.load(f)\n",
    "\n",
    "print(\"Configuración del dataset:\")\n",
    "for key, value in dataset_config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Cargar datos\n",
    "train_df = pd.read_csv('data/train_data.csv')\n",
    "val_df = pd.read_csv('data/val_data.csv')\n",
    "test_df = pd.read_csv('data/test_data.csv')\n",
    "\n",
    "print(f\"\\nDatasets cargados:\")\n",
    "print(f\"Train: {len(train_df)} ejemplos\")\n",
    "print(f\"Val: {len(val_df)} ejemplos\")\n",
    "print(f\"Test: {len(test_df)} ejemplos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recreación del Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhoWouldWinDataset(Dataset):\n",
    "    \"\"\"Dataset personalizado para el problema de argumentación\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, tokenizer, max_input_length=256, max_output_length=128):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Tokenizar input\n",
    "        input_encoding = self.tokenizer(\n",
    "            row['input'],\n",
    "            max_length=self.max_input_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenizar output\n",
    "        target_encoding = self.tokenizer(\n",
    "            row['output'],\n",
    "            max_length=self.max_output_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Preparar labels\n",
    "        labels = target_encoding['input_ids']\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "            'labels': labels.squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inicialización del Modelo y Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando T5-small...\n",
      "\n",
      "Parámetros totales: 60,506,624\n",
      "Parámetros entrenables: 60,506,624\n"
     ]
    }
   ],
   "source": [
    "# Cargar tokenizer y modelo\n",
    "print(\"Cargando T5-small...\")\n",
    "model_name = 't5-small'  # Modelo pequeño para recursos limitados\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Mover modelo a dispositivo\n",
    "model = model.to(device)\n",
    "\n",
    "# Información del modelo\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nParámetros totales: {total_params:,}\")\n",
    "print(f\"Parámetros entrenables: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creación de DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 3790\n",
      "Val batches: 474\n"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "BATCH_SIZE = 2  # Muy pequeño para memoria limitada\n",
    "MAX_INPUT_LENGTH = dataset_config['max_input_length']\n",
    "MAX_OUTPUT_LENGTH = dataset_config['max_output_length']\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = WhoWouldWinDataset(train_df, tokenizer, MAX_INPUT_LENGTH, MAX_OUTPUT_LENGTH)\n",
    "val_dataset = WhoWouldWinDataset(val_df, tokenizer, MAX_INPUT_LENGTH, MAX_OUTPUT_LENGTH)\n",
    "\n",
    "# Crear dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configuración de Hiperparámetros y Optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración de entrenamiento:\n",
      "Épocas: 3\n",
      "Learning rate: 0.0003\n",
      "Batch size efectivo: 16\n",
      "Pasos totales: 1421\n"
     ]
    }
   ],
   "source": [
    "# Hiperparámetros optimizados para recursos limitados\n",
    "EPOCHS = 3  # Pocas épocas para evitar overfitting\n",
    "LEARNING_RATE = 3e-4\n",
    "WARMUP_STEPS = 500\n",
    "GRADIENT_ACCUMULATION_STEPS = 8  # Para simular batch más grande\n",
    "MAX_GRAD_NORM = 1.0\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Calcular pasos totales\n",
    "total_steps = len(train_loader) * EPOCHS // GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "# Optimizador\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Configuración de entrenamiento:\")\n",
    "print(f\"Épocas: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Batch size efectivo: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"Pasos totales: {total_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Funciones de Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, device, accumulation_steps):\n",
    "    \"\"\"Entrena el modelo por una época\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Entrenando\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        # Mover batch a dispositivo\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss / accumulation_steps\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # Actualizar barra de progreso\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # Liberar memoria\n",
    "        del input_ids, attention_mask, labels, outputs, loss\n",
    "        torch.cuda.empty_cache() if device.type == 'cuda' else None\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, device):\n",
    "    \"\"\"Valida el modelo\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Validando\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # Liberar memoria\n",
    "            del input_ids, attention_mask, labels, outputs\n",
    "            torch.cuda.empty_cache() if device.type == 'cuda' else None\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Loop de Entrenamiento con Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando entrenamiento...\n",
      "\n",
      "\n",
      "==================================================\n",
      "Época 1/3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando:   0%|          | 0/3790 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.96 GiB. GPU 0 has a total capacity of 31.84 GiB of which 0 bytes is free. Of the allocated memory 41.57 GiB is allocated by PyTorch, and 109.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m start_time = time.time()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Entrenar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGRADIENT_ACCUMULATION_STEPS\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m train_losses.append(train_loss)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Validar\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, optimizer, scheduler, device, accumulation_steps)\u001b[39m\n\u001b[32m     13\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m loss = outputs.loss / accumulation_steps\n\u001b[32m     23\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1854\u001b[39m, in \u001b[36mT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1851\u001b[39m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[32m   1852\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1853\u001b[39m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m     encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1855\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1859\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1860\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1862\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1863\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[32m   1864\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1865\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1866\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1867\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1868\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1124\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1107\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1108\u001b[39m         layer_module.forward,\n\u001b[32m   1109\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1121\u001b[39m         cache_position,\n\u001b[32m   1122\u001b[39m     )\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:675\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    660\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    661\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    673\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    674\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    685\u001b[39m     hidden_states, past_key_value = self_attention_outputs[:\u001b[32m2\u001b[39m]\n\u001b[32m    686\u001b[39m     attention_outputs = self_attention_outputs[\u001b[32m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:593\u001b[39m, in \u001b[36mT5LayerSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    582\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    583\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    590\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    591\u001b[39m ):\n\u001b[32m    592\u001b[39m     normed_hidden_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m     hidden_states = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(attention_output[\u001b[32m0\u001b[39m])\n\u001b[32m    604\u001b[39m     outputs = (hidden_states,) + attention_output[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:552\u001b[39m, in \u001b[36mT5Attention.forward\u001b[39m\u001b[34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    549\u001b[39m scores += position_bias_masked\n\u001b[32m    551\u001b[39m \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m attn_weights = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.type_as(scores)\n\u001b[32m    553\u001b[39m attn_weights = nn.functional.dropout(attn_weights, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    555\u001b[39m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ezequiel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\functional.py:2149\u001b[39m, in \u001b[36msoftmax\u001b[39m\u001b[34m(input, dim, _stacklevel, dtype)\u001b[39m\n\u001b[32m   2147\u001b[39m     dim = _get_softmax_dim(\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m.dim(), _stacklevel)\n\u001b[32m   2148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2149\u001b[39m     ret = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2151\u001b[39m     ret = \u001b[38;5;28minput\u001b[39m.softmax(dim, dtype=dtype)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 5.96 GiB. GPU 0 has a total capacity of 31.84 GiB of which 0 bytes is free. Of the allocated memory 41.57 GiB is allocated by PyTorch, and 109.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Configuración de early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "patience_counter = 0\n",
    "\n",
    "# Historial de entrenamiento\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Crear directorio para guardar modelos\n",
    "os.makedirs('prod', exist_ok=True)\n",
    "\n",
    "print(\"\\nIniciando entrenamiento...\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Época {epoch + 1}/{EPOCHS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Entrenar\n",
    "    train_loss = train_epoch(\n",
    "        model, train_loader, optimizer, scheduler, device, GRADIENT_ACCUMULATION_STEPS\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validar\n",
    "    val_loss = validate_epoch(model, val_loader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nTiempo de época: {epoch_time/60:.2f} minutos\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Guardar mejor modelo\n",
    "        print(\"\\nGuardando mejor modelo...\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'config': {\n",
    "                'model_name': model_name,\n",
    "                'max_input_length': MAX_INPUT_LENGTH,\n",
    "                'max_output_length': MAX_OUTPUT_LENGTH,\n",
    "                'learning_rate': LEARNING_RATE,\n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'accumulation_steps': GRADIENT_ACCUMULATION_STEPS\n",
    "            }\n",
    "        }, 'prod/modelo.pth')\n",
    "        print(\"Modelo guardado en prod/modelo.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"\\nNo hay mejora. Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"\\nEarly stopping activado. Deteniendo entrenamiento.\")\n",
    "            break\n",
    "    \n",
    "    # Liberar memoria\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() if device.type == 'cuda' else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualización de Curvas de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXuxJREFUeJzt3Ql4FFXa9vGnOyuEXRJ2EAWRXRYXwFFUlE0GXtdhHMX9dcQZeXHFGRdkFB1QxA3FDXVEVBT0c0MEARVcQFBARVE2FWi2kBDI1l3f9RzsTCckIYFU+nT1/3ddRaqrq6ur++lOuOucOuVzHMcRAAAAAABQ5fxVv0kAAAAAAKAI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASwjdAABY4tJLL5Ujjzwy2ruBCHfddZf4fL5o7wYAIIYRugEAUfXTTz/J//7v/8pRRx0lqampUqdOHenTp49MnjxZ9u3bF+3d80RgLGvasmVLpbc5ffp0eeihh1zZ33j122+/mVqtWLEi2rsCAHBBohsbBQCgIt555x05//zzJSUlRS655BLp1KmT5OfnyyeffCI33XSTrF69WqZOnRrt3Yx5U6ZMkVq1ah2wvF69eocUuletWiWjRo2SePDPf/5Tbr31VtdD99ixY00vh+OOO87V5wIAVD9CNwAgKtatWyd/+tOfpFWrVjJ//nxp0qRJ0X0jR46UtWvXmlBeFXJyciQtLU3i1XnnnScNGzas9ufNzc2V5ORk8ftjt2NdYmKimQAAOFSx+1cQABDT/v3vf8uePXvkmWeeKRa4w9q0aSPXX3+9mV+/fr3pDj1t2rQD1tPl2jW3ZJfqb7/9Vv785z9L/fr15eSTT5aJEyea5Rs2bDhgG2PGjDHhcNeuXeb2xx9/bFrgW7ZsaVrhW7RoIf/3f/93QHd37Z592WWXSfPmzc16+jqGDh1q9vdgZs+ebVr2tUu9/pw1a1ap64VCIdOdu2PHjmbdRo0ame744X2tCgsWLDDvzauvvir33HOPeT36XGeccYY5+BHWt29fcyBE38NwF/XwOejhbcyYMcO0Djdr1kxq1qwpWVlZ5v7PP/9cBgwYIHXr1jXLTz31VPn000+L7Ue4dvqcen67tsTr+voe7927t9i6zz33nJx++umSkZFh3vsOHTqYFv2SdP/OPvtss389e/aUGjVqSOfOnc1t9cYbb5jb+np79Oghy5cvL3WfSvrPf/5j1tftNWjQwBxA2rRpU7F19P3S2upn8bTTTjOvW98X/exHvvfHH3+8mdfXGX5fIz/rr732WtFz6cGTv/zlL/Lrr79WqLYAgOjj0C0AICr+3//7f+Y87t69e7uyfQ3Nbdu2lXvvvVccxzHB6+abbzbBUruuR9JlZ511lgno4ZCjIe+vf/2rHHHEEfLFF1/II488Ir/88ou5L+zcc881XeD/9re/mXAXCARk7ty5snHjxnIHRPvggw/MYzUojh8/Xnbs2FEU3kvSgK0BTO//+9//bnoIPProoyYcamhNSko66Huxc+fOA5Zp623J7uX33XefaZW+8cYbZffu3SYcXnTRRSYwq3/84x9mub4PkyZNMstKdlsfN26cOYCh28jLyzPz2pNh4MCBJjjeeeed5jnCoVkPcJxwwgnFtnHBBRdI69atzXvz1VdfydNPP23C9f3331+0jgZsPRDxxz/+0bwW/Txde+215iCF9pSIpCFeD8Doe6mBVQ/ADBkyRJ544gm57bbbzOOUPp8+95o1a8ptndcDE7fffrtZ98orr5Rt27aZz8cpp5xi6hL5vurBET3YcM4555j1Z86cKbfccosJ+vqetG/fXu6++26544475Oqrr5Y//OEP5nHh70W49hrMdf+2bt1qxjvQ2pd8LgCApRwAAKrZ7t27Hf0TNHTo0Aqtv27dOrP+c889d8B9uvzOO+8suq3zumz48OEHrNurVy+nR48exZZ98cUXZv0XXnihaNnevXsPeOz48eMdn8/nbNiwwdzetWuXedyECROcyjruuOOcJk2aOJmZmUXLPvjgA7O9Vq1aFS37+OOPzbKXXnqp2OPff//9UpeXFH4vSpvatWtXtN5HH31klrVv397Jy8srWj558mSzfOXKlUXLBg8eXGwfS27jqKOOKvb+hUIhp23btk7//v3NfJiu07p1a+fMM888YH8vv/zyYtv+n//5H+eII44otqy0Gulz6PNH0n3VbS5evLho2Zw5c8yyGjVqFNVTPfnkk2a5vpaS+xS2fv16JyEhwbnnnnuKPY++R4mJicWWn3rqqQd8tvT9bdy4sXPuuecWLfvyyy9L/Xzn5+c7GRkZTqdOnZx9+/YVLX/77bfN+nfccccB7wEAwD50LwcAVLtwl+PatWu79hzXXHPNAcsuvPBCWbZsmRkxPeyVV14x3ZO1W3iYduONPB98+/btpuVRM364+7Guo6242j24Ml29N2/ebEapHjFihOk6HXbmmWealu9I2qqu6+h9ug/hSVuMtYX5o48+qtBzvv7666YFPnLSluaStEVVX1NYuNX1559/rvDr09cV+f7pa/3xxx9NS7O26Idfg76v2n190aJFpnW6vNrpfuhjw58bFfkc2vqu29Qu67qvejuSvq+9evUqun3iiSean9rSrqcQlFxe3uvV7ui6v9pqHVmTxo0bm54VJWuiddLW9TB9f7VlvyLv6dKlS03vCW2J1+7vYYMHD5Zjjz22ysY8AAC4i+7lAIBqp5cFU9nZ2a49h3ZPLq3L+ejRo03Q1m7FGqI12Go33/A+Ke0ert1933rrrQMCdTjQaVDX7s433HCDOc/6pJNOMl3YdRR2DWBlCZ9TrgGtpHbt2pnu1GEaVvX5tGt1aTSQVYR2e67IQGqRAVSFu9tX5qBCyfddX0M4jJdFX2P4uQ62H+E6afdq7aq+ZMmSA8731u1FHtAoub3wfXqufmnLy3u9+nr0c1Na/VTJ7v56ykDJc8L19XzzzTdyMOHPin4uStLQraP8AwDsR+gGAFQ7DU5NmzY1l56qiNIGslLBYLDMx0S2hIbpc2qrqZ7DraH7s88+MwE78lxh3aa2LOt50HrurYYbHflcB67Swb0iW2X1sll6brAOijZnzhxznq+ed6vnMHfr1k0Olz6XBu6XXnqp1PvT09OlKiUkJJS6fH8v/oop+b6H368JEyaUeTmskueFH2w/tKeCtpJrbR588EETnrUF+d133zXnmpdsOS9re4fyenXb+nl87733Sn18ZV8LAMD7CN0AgKjQVmG9Bre2VEZ2/S1NuKUzMzOz2PLSRiI/GO1irt11dbAsbfHWEaU1OIetXLlSfvjhB3n++edNq3WYdskuzdFHH21au3XSVlANlg888IAZ3bo0eom0yBbgSLpPJbf94YcfSp8+fUo9iBANZR0AKYu+hvCBln79+lXJPuigaTpIm/ZEiGzFrmh3+8Ohr0cDs7boH3PMMa6+p+HPin4utCt8JF0Wvh8AYDfO6QYARIWOJK4tyDr6s47IXJK2ZuoozeHApt2j9fzfSI8//niln1dHDdfWx5dfftl0LdfwH3kN73DLZGRLpM6H9yVMuzTrdahLBjI9T10DYVn0smIazDXUR557rKFeLy0VSc8b1pZ3HRG8pMLCwgMOQlQHfa9KnjNdHj3/XN8XHTFcLxFXko78XVml1Uj3qbTz1KuajkKuzz927NgDWqv1tp57Xlnhz1/JeuolzrSng46yHvmZ0lb27777zpzbDQCwHy3dAICo0CA2ffp00/Ksl03SVmW9pnF+fr4sXrzYBGLtzh2m4VwvaaU/NYxoANcW6crSEKPXTNZuyXpOuT5/JO2yrPuml7zSLuUa+HUgspLn+epzaxdnDcY6UJdetkqvta0HEPSazeXRLugamPT64Zdffrnpyq6XnNJLYEUGUx0YTC9zpevrgGR6WTM9Z1hbyfX90QMB55133kFfs16mqmS3Z6Xd6PV89MrQEK09BPTceL2MlW43sqdASXrpLb3kl543r69PB2vTa1Xre6st0/r+ast1Zej7oN3J9Xn1/dH37KmnnjK11YHq3KSfjX/961/m2u56PfZhw4aZAy16KTetv172Sz87ld2mXvpLw7VuS0O4Duqmrel66oO+Z/pZGD58eNElw/SSdHrteABADIj28OkAgPj2ww8/OFdddZVz5JFHOsnJyU7t2rWdPn36OI888oiTm5tb7BJRV1xxhVO3bl2zzgUXXOAEAoEyLxm2bdu2Mp/zqaeeMuvodiIvxRT27bffOv369XNq1arlNGzY0Ozf119/XeyyTtu3b3dGjhzpHHvssU5aWprZrxNPPNF59dVXK/S6X3/9dXOJrpSUFKdDhw7OG2+84YwYMaLUy3FNnTrVXOpML3Gl+9y5c2fn5ptvdn777bdDvmRY5KWxwpf7eu211w56qbY9e/Y4f/7zn5169eoVu8RZWdsIW758uXPOOeeYS3/pa9bHaQ3nzZt30Nrp8+ty3Z+wt956y+nSpYuTmppqPjv333+/8+yzzx6wnj6PXuasJF1P61fa6428DFzJS4ZF1u/kk082tddJPwe6vTVr1hS7ZFjHjh0PeGxpdX7zzTfN50AvO1byPX/llVecbt26mfetQYMGzkUXXeT88ssvpb7PAAD7+PSfaAd/AAAAAAC8iHO6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlyRKnAmFQvLbb79J7dq1xefzRXt3AAAAAAAxSK++nZ2dLU2bNhW/v+z27LgL3Rq4W7RoEe3dAAAAAAB4wKZNm6R58+Zl3h93oVtbuMNvTJ06dcTmFvlt27ZJenp6uUdNEB3Ux37UyG7Ux37UyG7Ux27Ux37UyF75wXyZ+OlEydmbI7efcbukJqWKrbKyskyDbjhjliXuQne4S7kGbttDd25urtlHfhHYh/rYjxrZjfrYjxrZjfrYjfrYjxrZHbpT0lKkUApNfWwO3WEHO22ZTxgAAAAAAC4hdAMAAAAA4BJCNwAAAAAALom7c7oBAAAAAHZK8ifJ9Sdebwa603kvIHQDAAAAAKwZlKxeaj3JT8k/6ABlsYLu5QAAAAAAuITQDQAAAACwQjAUlA9++kAWbFpg5r3AmtB93333me4Do0aNKne91157TY499lhJTU2Vzp07y7vvvltt+wgAAAAAcE/QCcqSX5bI0q1LzbwXWBG6v/zyS3nyySelS5cu5a63ePFiGT58uFxxxRWyfPlyGTZsmJlWrVpVbfsKAAAAAEDMhO49e/bIRRddJE899ZTUr1+/3HUnT54sAwYMkJtuuknat28v48aNk+7du8ujjz5abfsLAAAAAEDMhO6RI0fK4MGDpV+/fgddd8mSJQes179/f7McAAAAAADbRPWSYTNmzJCvvvrKdC+viC1btkijRo2KLdPburwseXl5ZgrLysoyP0OhkJlspfvmOI7V+xjPqI/9qJHdqI/9qJHdqI/dqI/9qJH9tXF+r4/NNarovkUtdG/atEmuv/56mTt3rhkUzS3jx4+XsWPHHrBcL7aem5srNhdw9+7d5sPm90e9QwJKoD72o0Z2oz72o0Z2oz52oz72o0b2yg/mS05OjslqgUBAUpPcy4qHKzs72+7QvWzZMvMm6jnZYcFgUBYtWmTO0dbW6YSEhGKPady4sWzdurXYMr2ty8syZswYGT16dLGW7hYtWkh6errUqVNHbP5FoKO5637yi8A+1Md+1Mhu1Md+1Mhu1Mdu1Md+1Mju0J2WlmbmMzIyrA7dFW08jlroPuOMM2TlypXFll122WXmcmC33HLLAYFb9erVS+bNm1fssmLaUq7Ly5KSkmKmkvTLZfsXTH8RxMJ+xivqYz9qZDfqYz9qZDfqYzfqYz9qZKcUX4pce/y1sn37dklJTLG6PhXdt6iF7tq1a0unTp2KLdMjGkcccUTR8ksuuUSaNWtmuogr7Y5+6qmnygMPPGAGX9NzwpcuXSpTp06NymsAAAAAAFTtwZCMtAyRnP3zXmDvYQMR2bhxo2zevLnodu/evWX69OkmZHft2lVmzpwps2fPPiC8AwAAAAAg8T56eUkLFiwo97Y6//zzzQQAAAAA8JZgKCgL1y+UzMxMGdJwiNXdyysq9l8BAAAAAMATgk5QFm5YKIt/W2zmvcCqlm78l691a2no94uvVi0dFk+kRo3/TpW5XZF1PXD0CAAAAABsROi2UUGB+DZurL7iJCcfemA/1LCfyEcPAAAAgPeRfGyUkCChL7+UXZs3S/3UVPHn5Yns2yeSm7v/Z8n5yt7W+YKC/z5ffv7+affuan2Nh9U6fyiP1YMLHhkBEQAAAEBsIHTbSLt7d+8uBYGAXhHene7fhYX/DeIHC+iHE+4j79ODB2HBoMiePfun6qKBu6rCfXKypOiBisaN9Vp3Za9L930AAAAgrhG645V279bzxXWqLqHQ/uB9KIH9cMK+4+x/fv0ZXnaYNEbXr+jKKSnV120/fJvu+wAAAIAV+J85qo+2+IbDYXXRoK1d6Q81sJdx29m3TwqysiQpGBRfaetqT4IwPdCgU3V239fQXZXd9iuyLbrvAwAAAAcgdMPbNARqGNSpbt0q26wTCsnOQEAyMjLEV1r38cju+1Xdsl/WfZHd9/X5s7P3T9X5Xldla31FHqu9COi+DwAA4BmJ/kS5stuVsn3HdjPvBd54FYBtotV9XwN4dXXbD9+O7L6/d+/+qTpp8C4llPtq1JD6etm9OnVEatas2rCvAwECAACgyvl9fmlWp5kk5SaZeS8gdANeoS2+Gi51qi4atHVAueo8R19vl9Z9PzOz2K5pR/cUt7vvV3XLfnn3JSXRfR8AACAGEboBHDoNgdrSrFN10tB9kMAeysmRrEBA6iQllX7ZvcqGfT24EM3u+3pQpbq67UeOvk/QBwAA1SgYCsriTYtl165dMrDhQPF74FRCQjeA2KMtzbVr75/KEgpJrobuqrrsXrj7fnWPvh/5/NHovq/B242wn5IiifpatIeCXnYv8j667wMAELeCTlA+/PlDycnJkbM6niVJkiSxjtANALHQfb+6ztHXKRj87z6Exwko0X3/cOlhkIZl3ald6atzQD69Tfd9AADgEkI3AMRC9/169arvefUyey635Du/nwLgz8/ff9m9yO77+vw6ZWVF55KG1Tn6PkEfAADPI3QDAIrTVl+dyuu+XwWX3dsWedk9bV2Pxuj7kd33c3L2T9WpooH+cMJ+ydseODcOAIBYQugGAESfnset53brVJ3d9ysyyF5VddsPTxrww8IHGnbtqr7XHe6+f5CA7ktNlToFBeLTmmh9wpOG9sr8dGtdt7dPLwQAQBUhdAMA4pOGqvBAcdVJu85X5zn6OulzVrL7vkbOahzBwE4WHzTw+XxSR0/P0IMiOrik1w56lHyMThwIARCjCN0AAESj+36dOtX3nOHu+5UI7KG9eyVn925Jq1FD/NorQLehrfTl/azIOofzmKravr6eir5vkQMLWiQuD4po6I6RgwZ6UKR2Xp749DSdij7Wov2v0GO0HhwIASqE0A0AgNcdSvf9UEhyAgFJq6rL7tlEQ7cG8Fg9aBAKSaiwUHKys6VWaqr4wgdF3N5/N19zRQ6E6DqFhRILNIpW48ky0RPuhRCDBw30wEit3Nz9B0a0t0iM7X+p63rkIEiiP1FGdB0hO3bsMPNe4I1XAQAAUNkWU52010EsijgoYgYj9MqBkCgeyKjK7TvBoDkokqYHRUo7wGP5/hcbe6I84dcWIwdDImk8rSUeFMsHDfz75/1+vxzp90v63r3iv6KeSNu2EusI3QAAALDnQIgH6BUa9gQCUjOWD4qUd7AgFg4aHOSnU1goe/fskZopKeUfGLFl/yt6ICS8jcixPGKQX0T0GiqhU04hdAMAAADwcNdx7XrtQXpgJDsQkBqxcmBEe4OUNb6GJQcyqmr7wWCBLPVvlbx9e6VX86YmgMc6b36LAAAAAMArwgPXxcIBgsMUDObLu4vukZycHDmh/bESoycBFeP9qgEAAAAAECWEbgAAAAAAXELoBgAAAADAJYRuAAAAAABcQugGAAAAAMAlhG4AAAAAAFzCJcMAAAAAAFZI9CfK8E7DZceOHWbeC7zxKgAAAAAAMc/v88sxRxwjgWDAzHuBN14FAAAAAAAWInQDAAAAAKwQDAVlxZYVsmr7KjPvBYRuAAAAAIAVgk5Q3lzzpry//n0z7wWEbgAAAAAAXELoBgAAAADAJYRuAAAAAABcQugGAAAAAMAlhG4AAAAAAFxC6AYAAAAAwCWJbm0YAAAAAIDKSPQnynntz5OdO3eaeS/wxqsAAAAAAMQ8v88vHTM6SkACZt4LvPEqAAAAAACwEKEbAAAAAGCFkBOS1YHVsmbnGjPvBXQvBwAAAABYoTBUKDO/myk5OTlyYtsTJTEh9iMrLd0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLYn/8dQAAAACAJyT4EmRou6Gyc+dOM+8FhG4AAAAAgBUS/AlyXOPjJOAPmHkvoHs5AAAAAAAuIXQDAAAAAKwQckLyw44f5KfMn8y8F0Q1dE+ZMkW6dOkiderUMVOvXr3kvffeK3P9adOmic/nKzalpqZW6z4DAAAAANxRGCqUl1e9LLPWzjLzXhDVc7qbN28u9913n7Rt21Ycx5Hnn39ehg4dKsuXL5eOHTuW+hgN52vWrCm6rcEbAAAAAAAbRTV0DxkypNjte+65x7R+f/bZZ2WGbg3ZjRs3rqY9BAAAAADAA+d0B4NBmTFjhuTk5Jhu5mXZs2ePtGrVSlq0aGFaxVevXl2t+wkAAAAAQMxcMmzlypUmZOfm5kqtWrVk1qxZ0qFDh1LXbdeunTz77LPmPPDdu3fLxIkTpXfv3iZ4a1f10uTl5ZkpLCsry/wMhUJmspXum3a5t3kf4xn1sR81shv1sR81shv1sRv1sR81sr82zu/1sblGFd23qIduDdIrVqwwIXrmzJkyYsQIWbhwYanBW8N5ZCu4Bu727dvLk08+KePGjSt1++PHj5exY8cesHzbtm0m6NtcQH1P9MPm91vTIQG/oz72o0Z2oz72o0Z2oz52oz72o0b2yg/mm97PmtUCgYCkJtk7cHZ2dnZshO7k5GRp06aNme/Ro4d8+eWXMnnyZBOkDyYpKUm6desma9euLXOdMWPGyOjRo4u1dGvX9PT0dDMom82/CPT8dd1PfhHYh/rYjxrZjfrYjxrZjfrYjfrYjxrZHbrT0tLMfEZGhtWhu6JX0op66C7tCxDZHfxg54Fr9/RBgwaVuU5KSoqZStIvl+1fMP1FEAv7Ga+oj/2okd2oj/2okd2oj92oj/2okZ2SJEkGtR0ku3btkqSEJKvrU9F9i2ro1lbogQMHSsuWLU3T/PTp02XBggUyZ84cc/8ll1wizZo1M13E1d133y0nnXSSaRnPzMyUCRMmyIYNG+TKK6+M5ssAAAAAAFSBBH+CnNDsBAkkBcy8F0Q1dGsffQ3Wmzdvlrp165oB0jRwn3nmmeb+jRs3Fjt6oEc7rrrqKtmyZYvUr1/fdEdfvHhxmQOvAQAAAAAQt6H7mWeeKfd+bfWONGnSJDMBAAAAALwn5IRkfeZ62ZG9QxqmNxS/PVe5PmTWndMNAAAAAIhPhaFCef7r580I5p2P7CyJCbEfWWP/sAEAAAAAAJYidAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOCS2B9/HQAAAADgCQm+BOl3VD/ZtWuXmfcCQjcAAAAAwAoJ/gTp06KPBFICZt4L6F4OAAAAAIBLCN0AAAAAACuEnJD8mvWrbM7ZbOa9gNANAAAAALBCYahQnl7+tLz03Utm3gsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLCN0AAAAAALiE0A0AAAAAgEsS3dowAAAAAACVkeBLkFNbnSqZmZlm3gsI3QAAAAAAKyT4E6TvkX0lEAiYeS+gezkAAAAAAC4hdAMAAAAArOA4jgRyArJ933Yz7wWEbgAAAACAFQpCBTJl6RSZtnqamfcCQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALiF0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOCSRLc2DAAAAABAZST4EqRX816SmZlp5r2A0A0AAAAAsEKCP0HOOvosCQQCZt4L6F4OAAAAAIBLCN0AAAAAACs4jiOZuZmyO2+3mfcCQjcAAAAAwAoFoQKZ/PlkeWrlU2beCwjdAAAAAAC4hNANAAAAAIBLCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASxLd2jAAAAAAAJXh9/mlZ9Oesjtzt5n3AkI3AAAAAMAKif5EGdx2sAQCATPvBd44dAAAAAAAgIUI3QAAAAAAKziOIzn5ObK3YK+Z9wJCNwAAAADACgWhApm4ZKI8/vXjZt4LCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLEt3aMAAAAAAAleH3+aVro66ye/duM+8FhG4AAAAAgBUS/Yky7NhhEggEzLwXeOPQAQAAAAAAFiJ0AwAAAACs4DiO5AfzzaTzXhDV0D1lyhTp0qWL1KlTx0y9evWS9957r9zHvPbaa3LsscdKamqqdO7cWd59991q218AAAAAgHsKQgUy/pPx8vDyh828F0Q1dDdv3lzuu+8+WbZsmSxdulROP/10GTp0qKxevbrU9RcvXizDhw+XK664QpYvXy7Dhg0z06pVq6p93wEAAAAAsDp0DxkyRAYNGiRt27aVY445Ru655x6pVauWfPbZZ6WuP3nyZBkwYIDcdNNN0r59exk3bpx0795dHn300WrfdwAAAAAAYuac7mAwKDNmzJCcnBzTzbw0S5YskX79+hVb1r9/f7McAAAAAADbRH0M9pUrV5qQnZuba1q5Z82aJR06dCh13S1btkijRo2KLdPburwseXl5ZgrLysoyP0OhkJlspfumAwfYvI/xjPrYjxrZjfrYjxrZjfrYjfrYjxrZXxvn9/rYXKOK7lvUQ3e7du1kxYoV5uLnM2fOlBEjRsjChQvLDN6VNX78eBk7duwBy7dt22aCvs0F1PdEP2x+vzUdEvA76mM/amQ36mM/amQ36mM36mM/amSv/GC+6f2sWU2v1Z2alCq2ys7Ojo3QnZycLG3atDHzPXr0kC+//NKcu/3kk08esG7jxo1l69atxZbpbV1eljFjxsjo0aOLtXS3aNFC0tPTzYjpNv8i8Pl8Zj/5RWAf6mM/amQ36mM/amQ36mM36mM/amR36E5LSzPzGRkZVoduvaJWTITu0r4Akd3BI2k39Hnz5smoUaOKls2dO7fMc8BVSkqKmUrSL5ftXzD9RRAL+xmvqI/9qJHdqI/9qJHdqI/dqI/9qJGdEiVROqR3kKyULElMSLS6PhXdt6iGbm2FHjhwoLRs2dI0zU+fPl0WLFggc+bMMfdfcskl0qxZM9NFXF1//fVy6qmnygMPPCCDBw82A6/ppcamTp0azZcBAAAAAKgCif5EuaDjBaZruc57QVRfhb6RGqw3b94sdevWlS5dupjAfeaZZ5r7N27cWOzoQe/evU0w/+c//ym33XabudTY7NmzpVOnTlF8FQAAAAAAWBi6n3nmmXLv11bvks4//3wzAQAAAABgO3s7yAMAAAAA4m4gtbELx8rEpRPNvBcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAC9epxsAAAAAgDC/zy9tGrSRrMQsM+8FhG4AAAAAgBUS/YlyUeeLJBAImHkv8MahAwAAAAAALEToBgAAAADAJYRuAAAAAIAV8oP5cu/H98pDXz1k5r2A0A0AAAAAsEZBqEAKQ4XiFYRuAAAAAABcQugGAAAAAMAlhG4AAAAAAFxC6AYAAAAAwCWEbgAAAAAAXJLo1oYBAAAAAKgMn/ikVb1Wku3PNvNeQOgGAAAAAFghKSFJLu16qQQCATPvBXQvBwAAAADAJYRuAAAAAABcQugGAAAAAFghP5gvExZPkMdWPGbmvYDQDQAAAACwxt6CvbKvcJ94BaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlyS6tWEAAAAAACrDJz5pUruJZDvZZt4LCN0AAAAAACskJSTJ1d2vlkAgYOa9gO7lAAAAAAC4hNANAAAAAIBLCN0AAAAAACsUBAtk8ueTZeo3U828F3BONwAAAADACo44kpmbKTn5OWbeC2jpBgAAAADAJYRuAAAAAABcQugGAAAAAMAlhG4AAAAAAFxC6AYAAAAAwCWMXg4AAAAAsIJPfJJeM11Sg6lm3gsI3QAAAAAAKyQlJMm1x18rgUDAzHsB3csBAAAAAHAJoRsAAAAAAJcQugEAAAAAVigIFsjjXz4uz616zsx7Aed0AwAAAACs4Igj2/Zuk5zcHDPvBbR0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJGLwcAAAAAWMEnPqmXWk8SChLMvBcQugEAAAAAVkhKSJLrT7xeAoGAmfcCupcDAAAAAOASQjcAAAAAAC4hdAMAAAAArFAQLJCpX02VF7990cx7QVRD9/jx4+X444+X2rVrS0ZGhgwbNkzWrFlT7mOmTZsmPp+v2JSamlpt+wwAAAAAcIcjjmzO3ixb9241814Q1dC9cOFCGTlypHz22Wcyd+5cKSgokLPOOktycnLKfVydOnVk8+bNRdOGDRuqbZ8BAAAAAIiJ0cvff//9A1qxtcV72bJlcsopp5T5OG3dbty4cTXsIQAAAAAAHrlk2O7du83PBg0alLvenj17pFWrVhIKhaR79+5y7733SseOHUtdNy8vz0xhWVlZ5qc+Vidb6b45jmP1PsYz6mM/amQ36mM/amQ36mM36mM/amR/bZzf62NzjSq6b4k27fCoUaOkT58+0qlTpzLXa9eunTz77LPSpUsXE9InTpwovXv3ltWrV0vz5s1LPW987NixByzftm2b5Obmiq30/dDXpx82v5/x7mxDfexHjexGfexHjexGfexGfexHjeyVH8w3pxtrVtNrdacm2Tt+V3Z2dmyFbj23e9WqVfLJJ5+Uu16vXr3MFKaBu3379vLkk0/KuHHjDlh/zJgxMnr06GIt3S1atJD09HRzbrjNvwi0G73uJ78I7EN97EeN7EZ97EeN7EZ97EZ97EeN7A7daWlpZl5PPbY5dFd0QG8rQvd1110nb7/9tixatKjU1uryJCUlSbdu3WTt2rWl3p+SkmKmkvTLZfsXTH8RxMJ+xivqYz9qZDfqYz9qZDfqYzfqYz9qZCe/45e05DRx8h3r61PRfYtq6NbuHH/7299k1qxZsmDBAmndunWltxEMBmXlypUyaNAgV/YRAAAAAFA9khOS5abeN5mu5TrvBYnR7lI+ffp0efPNN821urds2WKW161bV2rUqGHmL7nkEmnWrJk5N1vdfffdctJJJ0mbNm0kMzNTJkyYYC4ZduWVV0bzpQAAAAAAYFfonjJlivnZt2/fYsufe+45ufTSS838xo0bizXb79q1S6666ioT0OvXry89evSQxYsXS4cOHap57wEAAAAAsLx7+cFot/NIkyZNMhMAAAAAwFsKggXy4jcvSnZWtlxzxDWS4j9wfK5YY8VAagAAAAAAOOLIhswN5rJhOu8F9g4FBwAAAABAjCN0AwAAAADgEkI3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAArJHkT5JEv3cutOWdVwIAAAAAiGnJCcly2x9uk0AgYOa9gNBdCsdxpLCwUILBYNT2IRQKSUFBgeTm5orfT4eEw5GUlCQJCQnR3g0AAAAAcYjQXUJ+fr5s3rxZ9u7dG/Xgr8E7OztbfD5fVPcl1un717x5c6lVq1a0dwUAAABAnCF0R9CQu27dOtMq2rRpU0lOTo5a4A23ticmJhK6D/N93LZtm/zyyy/Stm1bWrwBAAAAixWGCuXllS9LVlaWXNXwKkn2x34Xc0J3iVZuDd4tWrSQmjVrRnVfCN1VJz09XdavX2+66xO6AQAAAHuFnJCs3blWcnJyzLwXcLJwKTiH2ls4aAEAAAAgWkiXAAAAAAC4hNCNMh155JHy0EMPRXs3AAAAACBmEbo90n26vOmuu+46pO1++eWXcvXVVx/WvvXt21dGjRp1WNsAAAAAgFjFQGoeoJc4C3vllVfkjjvukDVr1hQti7xUlg7Qptcf1wHaKjIAGQAAAADg0NHS7QGNGzcumurWrWtat8O3v//+e6ldu7a899570qNHD0lJSZFPPvlEfvrpJxk6dKg0atTIhPLjjz9ePvzww3K7l+t2n376afmf//kfM7q7XoLrrbfeOqx9f/3116Vjx45mv/T5HnjggWL3P/744+Z5UlNTzb6ed955RffNnDlTOnfuLDVq1JAjjjhC+vXrZ0Y5BAAAAABb0NJ9EI4jsndvdJ43uQovSXfrrbfKxIkT5aijjpL69evLpk2bZNCgQXLPPfeYwPvCCy/IkCFDTAt5y5Yty9zO2LFj5d///rdMmDBBHnnkEbnoootkw4YN0qBBg0rv07Jly+SCCy4w3d8vvPBCWbx4sVx77bUmQF966aWydOlS+fvf/y4vvvii9O7dW3bu3Ckff/xxUev+8OHDzb7oQYDs7Gxzn7bkAwAAAIhNyQnJcuepd0ogEDDzXkDoPggN3BG9s6uRT3btEqlbt2q2dvfdd8uZZ55ZdFtDcteuXYtujxs3TmbNmmVarq+77royt6NhWMOuuvfee+Xhhx+WL774QgYMGFDpfXrwwQfljDPOkNtvv93cPuaYY+Tbb781gV6fZ+PGjZKWliZnn322aa1v1aqVdOvWrSh063XMzznnHLNcaas3AAAAAMR893JtJf3ll1+Kbmvo0sGypk6dWpX7hirUs2fPYrf37NkjN954o7Rv317q1atnuph/9913JuiWp0uXLkXzGojr1KljjkIdCn2+Pn36FFumt3/88Udz3rkeJNBAra3zF198sbz00kuy9/duB3rAQAO7Bu3zzz9fnnrqKdmlRykAAAAAINZD95///Gf56KOPzPyWLVtMONLg/Y9//MO0qHpJzZoaUKt/ys52zHNXFQ3IkTRwa8u2tlZrt+wVK1aYAJufn1/udpKSkord1vO8Q6GQuEFbt7/66it5+eWXpUmTJmaAOA3bmZmZkpCQIHPnzjXnqnfo0MF0dW/Xrp2sW7fOlX0BAAAA4L7CUKG8uvpVeeunt8x83IbuVatWyQknnGDmX331VenUqZM5H1dbIqdNmyZe4vNpYI3OpM/tlk8//dR04dbzoTVs66Br69evl+qkrey6HyX3S7uZa6hWOsq6DpCm525/8803Zh/nz59fFPi1ZVzPM1++fLkkJyebAwkAAAAAYlPICcl327+TH3b9YObj9pzugoICM/iW0hGv//jHP5r5Y489ttjlq2AvHRH8jTfeMIOnaXjV86rdarHetm2baUmPpC3XN9xwgxk1Xc8n14HUlixZIo8++qgZsVy9/fbb8vPPP8spp5xiBn979913zT5qi/bnn38u8+bNk7POOksyMjLMbX0eDfIAAAAAENMt3XqJpyeeeMJ0S9YuvuFBtH777Tcz8jTsp4OYaZDVUcE1ePfv31+6d+/uynNNnz7dDIAWOek52Pp82lNixowZpreEdh/X0xO0BV7pueZ6YOD00083YVo/c9rVXD9/ei75okWLzAjs2jL+z3/+01xubODAga68BgAAAAA4FD7nEK6xtGDBAtMtOSsrS0aMGCHPPvusWX7bbbeZ60JrULKV7rNey3r37t0muEXKzc015wS3bt3aXBc6mrQsOjq3dq/WlmgcOjfqqi3uOoCctrL7/Vzu3kbUyG7Ux37UyG7Ux27Ux37UyF75wXy5Z9E9kpOTI//q/y9JTYpuLjvUbHnY3cv79u0r27dvN0+iraVhV199tdSsytG/AAAAAACIYYd0WGffvn2Sl5dXFLg3bNggDz30kKxZs8YcLQIAAAAAAIcYuocOHSovvPCCmdfLN5144onmfNphw4bJlClTqnofAQAAAACIn9Ct107+wx/+YOZnzpwpjRo1Mq3dGsQffvjhqt5HAAAAAEAcSPInyZiTx8jfu/3dzMdt6N67d6/Url3bzH/wwQdyzjnnmAEITjrpJBO+AQAAAACoLB1EOjkh2UxeGVD6kEJ3mzZtZPbs2bJp0yaZM2eOuVay0hEAyxu1DQAAAACAeHJIoVuvp3zjjTfKkUceKSeccIL06tWrqNVbr8EMAAAAAEBlFYYKZfb3s+W9de+ZeS84pEuGnXfeeXLyySfL5s2bpWvXrkXLzzjjDHP9bgAAAAAAKivkhOTrrV+b63TrfNyGbtW4cWMz/fLLL+Z28+bNTas3AAAAAAA4jO7loVBI7r77bqlbt660atXKTPXq1ZNx48aZ+xCb+vbtK6NGjYr2bgAAAABAfIfuf/zjH/Loo4/KfffdJ8uXLzfTvffeK4888ojcfvvtVb+XKNeQIUNkwIABpd738ccfm1H/vvnmm8N+nmnTppmDKwAAAAAAF7uXP//88/L000/LH//4x6JlXbp0kWbNmsm1114r99xzz6FsFofoiiuukHPPPdd09ddu/pGee+456dmzp6kPAAAAACAGWrp37twpxx577AHLdZneh+p19tlnS3p6ummJjrRnzx557bXXTCjfsWOHDB8+3BwYqVmzpnTu3FlefvnlKt2PjRs3ytChQ6VWrVrm0nEXXHCBbN26tej+r7/+Wk477TRzjXe9v0ePHrJ06VJzn17fXVvs69evL2lpadKxY0d59913q3T/AAAAACAmWrp1xHLtXv7www8XW67LPNei6jgie/dG53mTkyu0amJiolxyySUmdGvX//BF5DVwB4NBE7Y1gGvIveWWW0zgfeedd+Tiiy+Wo48+ukoGwNNz+cOBe+HChVJYWCgjR46UCy+8UBYsWGDWueiii8wl5aZMmSIJCQmyYsUKSUpKMvfpuvn5+bJo0SITur/99luzLQAAAACIu9D973//WwYPHiwffvhh0TW6lyxZIps2bfJe66QG7iiEPxObd+0SqVu3QutffvnlMmHCBBN4dUC0cNdy7XauA97ppNdWD/vb3/4mc+bMkVdffbVKQve8efNk5cqVsm7dOmnRooVZ9sILL5gW6y+//FKOP/540xJ+0003FfWSaNu2bdHj9T7dV22BV0cdddRh7xMAAACA2JLkT5Ibe90o27ZtM/Nx27381FNPlR9++MFckzszM9NM55xzjqxevVpefPHFqt9LHJQG2d69e8uzzz5rbq9du9YMoqZdy5W2eOvo8hpqGzRoYFqRNXRr2K0K3333nQnb4cCtOnToYAZe0/vU6NGj5corr5R+/fqZQfh++umnonX//ve/y7/+9S/p06eP3HnnnVUy8BsAAACA2OLz+SQtOU1qJtUs6sEbl6FbNW3a1AyY9vrrr5tJA9OuXbvkmWeeEU+pWVNPjq72ycnO3v/claABW2uRnZ1tWrm167geIFHaCj558mTTvfyjjz4yXbv79+9vunRXl7vuusscmNFeEvPnzzehfNasWeY+DeM///yz6fKuLeY6+JuOhg8AAAAAcRm644YeXUlLi85UySM7OnCZ3++X6dOnm67d2uU8fHTo008/Nedc/+UvfzHn5Gv3be2tUFXat29vTi/QKUzPy9ZeEBquw4455hj5v//7P/nggw9M7wg9OBCmreTXXHONvPHGG3LDDTfIU089VWX7BwAAAMB+haFCeefHd+TDDR+a+bg9pxt20i7jOnDZmDFjJCsrSy699NKi+/T86ZkzZ8rixYvNCOEPPvigGVk8MhBXhHZT11bySCkpKabLuHZd18HSHnroITOQml4+TlvatdV637595nzu8847T1q3bm0ub6bneut53GrUqFEycOBAE8q1x4S2xmuQBwAAABA/Qk5Ilv62VHJycuQ85zzxAkK3x2gXc+3iP2jQIHMKQNg///lP031bu5TrJcOuvvpqGTZsmOzevbtS29dR0HUE8kjajV3PIX/zzTfNAG2nnHKKaXEfMGBAURdxHa1cL1umo6xr2G/YsKFp6R47dmxRmNcRzDWM6+jq+thJkyZVyXsCAAAAADERujUklUe7EiO6dDR5Ry83VoIOnjZ79uxyHxu+tFdZtOU8svW8pJYtW5rgXZrk5ORyrwvO+dsAAAAAJN5Dt1526mD3a0smAAAAAACoZOiOHPQKAAAAAACUj9HLAQAAAABwCaEbAAAAAACXMHo5AAAAAMAKSf4kuf7E62Xbtm1m3gsI3aUobfRvxC7qCQAAAMQGn88n9VLrSX5Kvpn3ArqXR0hK2n8kZe/evdHeFVSh/Pz8omuFAwAAAEB1oqU7goayevXqSSAQMLdr1qwZtaMr2jpbWFgoiYmJnjnCEw2hUMh0TdFa6nsJAAAAwF7BUFDm/jRXMjMz5dyG54rfH/vtxFFNIePHj5c33nhDvv/+e6lRo4b07t1b7r//fmnXrl25j3vttdfk9ttvl/Xr10vbtm3NYwYNGlQl+9S4cWPzMxy8o0VDtwZG/ZARug+PvoctW7bkfQQAAAAsF3SCsuSXJZKTkyPDnGGSJLF/XndUQ/fChQtl5MiRcvzxx5tW3dtuu03OOuss+fbbbyUtLa3UxyxevFiGDx9uAvvZZ58t06dPl2HDhslXX30lnTp1Oux90mDWpEkTycjIkIKCAokWDdw7duyQI444whNHd6IpOTmZ9xAAAABA/IXu999/v9jtadOmmbC7bNkyOeWUU0p9zOTJk2XAgAFy0003mdvjxo2TuXPnyqOPPipPPPFElXY1j+Y5wBq69Rzz1NRUAiMAAAAAxCirTnLdvXu3+dmgQYMy11myZImMHj262LL+/fvL7NmzS10/Ly/PTGFZWVlFoVYnW+m+hbuYwz7Ux37UyG7Ux37UyG7Ux27Ux37UyP7aOL/Xx+YaVXTfEm3a4VGjRkmfPn3K7Sa+ZcsWadSoUbFleluXl0a7oY8dO/aA5Tq4Vm5urthK3w89CKEfNlq67UN97EeN7EZ97EeN7EZ97EZ97EeN7JUfzDfnc2tW03G2UpNSxVbZ2dmxFbr13O5Vq1bJJ598UqXbHTNmTLGWcW3pbtGihaSnp0udOnXE5l8Een657ie/COxDfexHjexGfexHjexGfexGfexHjewO3Wm/j++lpx7bHLr1VOCYCd3XXXedvP3227Jo0SJp3rz5QUcX37p1a7Flejs86nhJKSkpZipJv1y2f8H0F0Es7Ge8oj72o0Z2oz72o0Z2oz52oz72o0Z28jv7r94UC/Wp6L5F9RVodw4N3LNmzZL58+dL69atD/qYXr16ybx584ot04HUdDkAAAAAIHYl+ZPkrz3/Kpd2vNTMe0FitLuU6yW/3nzzTaldu3bRedl169Y11+1Wl1xyiTRr1sycm62uv/56OfXUU+WBBx6QwYMHy4wZM2Tp0qUyderUaL4UAAAAAMBh8vl8kpGWIZKzf94LotrSPWXKFDOAQd++fc21scPTK6+8UrTOxo0bZfPmzUW3e/fubYK6huyuXbvKzJkzzcjlVXGNbgAAAAAAPNPSrd3LD2bBggUHLDv//PPNBAAAAADwjmAoKAvXL5TMzEwZ0nCI1ed0V1TsvwIAAAAAgCcEnaAs3LBQFv+22Mx7AaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAADw4nW6AQAAAAAIS/QnypXdrpTtO7abeS/wxqsAAAAAAMQ8v88vzeo0k6TcJDPvBd54FQAAAAAAWIjQDQAAAACwQjAUlE83fSpfbPnCzHsBoRsAAAAAYIWgE5QPf/5QFv2yyMx7AaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwSaJbGwYAAAAAoDIS/YkyousI2bFjh5n3Am+8CgAAAABAzPP7/HJkvSOlZn5NM+8F3ngVAAAAAABYiNANAAAAALBCMBSUL379QpYHlpt5LyB0AwAAAACsEHSC8t7a92Texnlm3gsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLCN0AAAAAALiE0A0AAAAAgEsS3dowAAAAAACVkehPlOGdhsuOHTvMvBd441UAAAAAAGKe3+eXY444RgLBgJn3Am+8CgAAAAAALEToBgAAAABYIRgKyootK2TV9lVm3gsI3QAAAAAAKwSdoLy55k15f/37Zt4LCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAAIBLEt3aMAAAAAAAlZHoT5Tz2p8nO3fuNPNe4I1XAQAAAACIeX6fXzpmdJSABMy8F3jjVQAAAAAAYCFCNwAAAADACiEnJKsDq2XNzjVm3gvoXg4AAAAAsEJhqFBmfjdTcnJy5MS2J0piQuxHVlq6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAl8T++OsAAAAAAE9I8CXI0HZDZefOnWbeCwjdAAAAAAArJPgT5LjGx0nAHzDzXkD3cgAAAAAAXELoBgAAAABYIeSE5IcdP8hPmT+ZeS+IauhetGiRDBkyRJo2bSo+n09mz55d7voLFiww65WctmzZUm37DAAAAABwR2GoUF5e9bLMWjvLzHtBVEN3Tk6OdO3aVR577LFKPW7NmjWyefPmoikjI8O1fQQAAAAAICYHUhs4cKCZKktDdr169VzZJwAAAAAA4nr08uOOO07y8vKkU6dOctddd0mfPn3KXFfX0yksKyvL/AyFQmayle6b4zhW72M8oz72o0Z2oz72o0Z2oz52oz72o0b218b5vT4216ii+xZTobtJkybyxBNPSM+ePU2Qfvrpp6Vv377y+eefS/fu3Ut9zPjx42Xs2LEHLN+2bZvk5uaKzQXcvXu3+bD5/Yx3ZxvqYz9qZDfqYz9qZDfqYzfqYz9qZK/8YL45DVmzWiAQkNSkVLFVdna290J3u3btzBTWu3dv+emnn2TSpEny4osvlvqYMWPGyOjRo4u1dLdo0ULS09OlTp06YvMvAh0kTveTXwT2oT72o0Z2oz72o0Z2oz52oz72o0Z2h+60tLSi04ptDt2pqaneC92lOeGEE+STTz4p8/6UlBQzlaRfLtu/YPqLIBb2M15RH/tRI7tRH/tRI7tRH7tRH/tRIzv5HX/RVapsr09F9y3mQ/eKFStMt3MAAAAAQGxL8CXIwDYDZdeuXWbeC6Iauvfs2SNr164tur1u3ToTohs0aCAtW7Y0XcN//fVXeeGFF8z9Dz30kLRu3Vo6duxo+vjrOd3z58+XDz74IIqvAgAAAABQFRL8CXJCsxMkkBQw814Q1dC9dOlSOe2004puh8+9HjFihEybNs1cg3vjxo1F9+fn58sNN9xggnjNmjWlS5cu8uGHHxbbBgAAAAAAtohq6NaRx3XEwLJo8I508803mwkAAAAA4D0hJyTrM9fLjuwd0jC9ofjF3nO6Kyrmz+kGAAAAAHhDYahQnv/6eXPZsM5HdpbEhNiPrLF/2AAAAAAAAEsRugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHBJ7I+/DgAAAADwhARfgvQ7qp/s2rXLzHsBoRsAAAAAYIUEf4L0adFHAikBM+8FdC8HAAAAAMAlhG4AAAAAgBVCTkh+zfpVNudsNvNeQOgGAAAAAFihMFQoTy9/Wl767iUz7wWEbgAAAAAAXELoBgAAAADAJYRuAAAAAABcQugGAAAAAMAlhG4AAAAAAFxC6AYAAAAAwCWJbm0YAAAAAIDKSPAlyKmtTpXMzEwz7wWEbgAAAACAFRL8CdL3yL4SCATMvBfQvRwAAAAAAJcQugEAAAAAVnAcRwI5Adm+b7uZ9wJCNwAAAADACgWhApmydIpMWz3NzHsBoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHBJolsbBgAAAACgMhJ8CdKreS/JzMw0815A6AYAAAAAWCHBnyBnHX2WBAIBM+8FdC8HAAAAAMAlhG4AAAAAgBUcx5HM3EzZnbfbzHsBoRsAAAAAYIWCUIFM/nyyPLXyKTPvBYRuAAAAAABcQugGAAAAAMAlhG4AAAAAAFxC6AYAAAAAwCWEbgAAAAAAXELoBgAAAADAJYlubRgAAAAAgMrw+/zSs2lP2Z2528x7AaEbAAAAAGCFRH+iDG47WAKBgJn3Am8cOgAAAAAAwEKEbgAAAACAFRzHkZz8HNlbsNfMewGhGwAAAABghYJQgUxcMlEe//pxM+8FhG4AAAAAAFxC6AYAAAAAwCWEbgAAAAAAXELoBgAAAADAJYRuAAAAAABcQugGAAAAAMAliW5tGAAAAACAyvD7/NK1UVfZvXu3mfcCQjcAAAAAwAqJ/kQZduwwCQQCZt4LvHHoAAAAAAAACxG6AQAAAABWcBxH8oP5ZtJ5L4hq6F60aJEMGTJEmjZtKj6fT2bPnn3QxyxYsEC6d+8uKSkp0qZNG5k2bVq17CsAAAAAwF0FoQIZ/8l4eXj5w2beC6IaunNycqRr167y2GOPVWj9devWyeDBg+W0006TFStWyKhRo+TKK6+UOXPmuL6vAAAAAABUVlTPTB84cKCZKuqJJ56Q1q1bywMPPGBut2/fXj755BOZNGmS9O/f38U9BQAAAADA4+d0L1myRPr161dsmYZtXQ4AAAAAgG1iagz2LVu2SKNGjYot09tZWVmyb98+qVGjxgGPycvLM1OYrqtCoZCZbKX7pgMH2LyP8Yz62I8a2Y362I8a2Y362I362I8a2V8b5/f62Fyjiu5bTIXuQzF+/HgZO3bsAcu3bdsmubm5YnMB9YLw+mHz+2OqQ0JcoD72o0Z2oz72o0Z2oz52oz72o0b2yg/mm7G/NKvptbpTk1LFVtnZ2d4L3Y0bN5atW7cWW6a369SpU2ortxozZoyMHj26WEt3ixYtJD093TzO5l8EOqK77ie/COxDfexHjexGfexHjexGfexGfexHjewO3WlpaWY+IyPD6tCdmprqvdDdq1cveffdd4stmzt3rlleFr20mE4l6ZfL9i+Y/iKIhf2MV9THftTIbtTHftTIbtTHbtTHftTITomSKB3SO0hWSpYkJiRaXZ+K7ltUQ/eePXtk7dq1xS4JppcCa9CggbRs2dK0Uv/666/ywgsvmPuvueYaefTRR+Xmm2+Wyy+/XObPny+vvvqqvPPOO1F8FQAAAACAqpDoT5QLOl5gupbrvBdE9bDB0qVLpVu3bmZS2g1c5++44w5ze/PmzbJx48ai9fVyYRqwtXVbr++tlw57+umnuVwYAAAAAMBKUT100LdvXzN4QVmmTZtW6mOWL1/u8p4BAAAAAHD47O0gDwAAAACIu4HUxi4cKxOXTjTzXkDoBgAAAADAJYRuAAAAAABcQugGAAAAAMAlhG4AAAAAAFxC6AYAAAAAwCWEbgAAAAAAvHidbgAAAAAAwvw+v7Rp0EayErPMvBcQugEAAAAAVkj0J8pFnS+SQCBg5r3AG4cOAAAAAACwEKEbAAAAAACXELoBAAAAAFbID+bLvR/fKw999ZCZ9wJCNwAAAADAGgWhAikMFYpXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwSaJbGwYAAAAAoDJ84pNW9VpJtj/bzHsBoRsAAAAAYIWkhCS5tOulEggEzLwX0L0cAAAAAACXELoBAAAAAHAJoRsAAAAAYIX8YL5MWDxBHlvxmJn3AkI3AAAAAMAaewv2yr7CfeIVhG4AAAAAAFxC6AYAAAAAwCWEbgAAAAAAXELoBgAAAADAJYRuAAAAAABckujWhgEAAAAAqAyf+KRJ7SaS7WSbeS8gdAMAAAAArJCUkCRXd79aAoGAmfcCupcDAAAAAOASQjcAAAAAAC4hdAMAAAAArFAQLJDJn0+Wqd9MNfNewDndAAAAAAArOOJIZm6m5OTnmHkvoKUbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlzB6OQAAAADACj7xSXrNdEkNppp5LyB0AwAAAACskJSQJNcef60EAgEz7wV0LwcAAAAAwCWEbgAAAAAAXELoBgAAAABYoSBYII9/+bg8t+o5M+8FnNMNAAAAALCCI45s27tNcnJzzLwX0NINAAAAAIBLCN0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASxi93FI33uiTvLxaUqeOT5KSxEyJifunyPmSt6t6PZ8v2u8EAAAAgHjhE5/US60nCQUJZt4LCN0WCoVEJk3SD1itaO+KJCREJ+xHYz2/n4MMAAAAQDQlJSTJ9SdeL4FAwMx7AaHbQo4jcsstjmRl7ZXk5JpSWOiTwkIxU0GBlDpf3n0VXa80weD+KS9P4kLFQ7xPHOcIqVHDZ93Bg4rexwEGAAAAwH2Ebgtp6/K99zoSCGRLRkYN8ft91RL0NVxXZYi3eT3tTVAavV+ng9OaxPaRN23Zt/2AweGsp68vN3f/51oPMHCQAQAAAHEbuh977DGZMGGCbNmyRbp27SqPPPKInHDCCaWuO23aNLnsssuKLUtJSZFc/d81DpkGknBgiQcauiODeWVDfH5+SHbsyJSaNetJKOS3/iBDWe+B9mDwbi8GHSeycdEt2w4KuLkeBxgAAECsKggWyDPLn5HsrGz5+xF/lxR/isS6qEesV155RUaPHi1PPPGEnHjiifLQQw9J//79Zc2aNZKRkVHqY+rUqWPuD/PxP0xUkraCJifvnw6FBtZAIF/0I6rbspn2YtD9tfmgQGXWO9g2yurFUN5pFF6jn0mbDwroT93HnJxkadhw//fwULenPYP4EwAAgHc44sjm7M2SszfHzHtB1EP3gw8+KFdddVVR67WG73feeUeeffZZufXWW0t9jIbsxo3/24IFoGwaSDSY6BQPNHRrl3LtjfDbb9ukfv100xvBhgMGbqxX1nuQn79/spcerWpQJVuyvedBVa5n+0E+AABgWejOz8+XZcuWyZgxY4qW+f1+6devnyxZsqTMx+3Zs0datWoloVBIunfvLvfee6907NixmvYagM00lOikBxlq13akQQPvBpVwLwabDwqUvZ4j+/YVis+XKAUF/x0ssrxt6MGU0oTvj4ezjMK9GNwI+wfe9sm+fbWkVi1f0fdKD+KV9bO8+6riMW6ta+O+AAC8Jaqhe/v27RIMBqVRo0bFluvt77//vtTHtGvXzrSCd+nSRXbv3i0TJ06U3r17y+rVq6V58+YHrJ+Xl2emsKysLPNTA7tOttJ9cxzH6n2MZ9THfvFSI/0PugYlnWrUkJihddm2bbukp6ebg60Ve0zxAR/dOCgQ3n7x9XyHtL3DOV1CnzP6vRjsuHRlvPL7nYMEdK1Phvl58HWr72BERR8T3QMjjuuvUTvI7tmTInXrOuL3h+LmgFEsHTSKl/8nxKLQ77UJ18fmGlV036LevbyyevXqZaYwDdzt27eXJ598UsaNG3fA+uPHj5exY8cesHzbtm1WD76mBdSDCvphq+h/SFF9qI/9qFH81CfcMus14QMAwaAv4qBA+ABA5IEA30HX022FDx78977I7fx3vfC8Bns9aJ2UlCKOs/9/0vp/i/09LPSyif+9HZ7Cy0u/T3/6Irax/3VGrhu53dKer/T7im+3tOePfHxpz1f6ffu3W/ry8OQr477DTx66b+HPQdliKOFYpbret/oSj3y+0g8ClVx+4MEM5yAHOQ58fGnLw39S/rus+HZVeHkoVEcSE4Pi9wdL3Ff285W23QMPUjhl7MuB95X2PpV1X/ix5T1n2QdM9p8bXd59pR94KX+74bpWpOb+Yj9Lf079Wejky8aN+yQ/v0DWrdsmR9SzdyC17OzsCq0X1f+mNGzYUBISEmTr1q3Fluvtip6znZSUJN26dZO1a9eWer92XdeB2iJbulu0aGFaV3RANpv/Q6rnrlemFQjVh/rYjxrZjfrESm+EbElPr0uNylTWAD9OmUG95LKyfh5snWAwJNu375T69RuIz+ev8Hbd2JdDWVcd+vZ9Vb7fVf9aHRMYEhL08qIV2187anT4ByQiD0bZf5DI3jAX1xLyRf6QJiJpcn7jDBl6tr11Sk1NtT90JycnS48ePWTevHkybNiwoj/yevu6666r0Da0e/rKlStl0KBBpd6vlxPTqST9D4Tt/4nQ/5DGwn7GK+pjP2pkN+pjP2p0eNwcwFIDTb16IcnIoD420tAdCOwyV+LZfypA7Ci7x0h0DxZU9fYLC7XHVZbUqlXHHLiKnQMj9u5LVe13UET2JdUwt1NS9v8dslVF9y3qHfK0FXrEiBHSs2dPc21uvWRYTk5O0Wjml1xyiTRr1sx0E1d33323nHTSSdKmTRvJzMw01/fesGGDXHnllVF+JQAAAEBsizw328tXPtFAFwjkSkZGnaLu3LBFsoRCN0kgEJCMjEO8vq9loh66L7zwQnN+9R133CFbtmyR4447Tt5///2iwdU2btxY7AjCrl27zCXGdN369eublvLFixdLhw4dovgqAAAAAACwMHQr7UpeVnfyBQsWFLs9adIkMwEAAAAAYDs6UwAAAAAArFAQLJBpX0+TV9a8Yua9wIqWbgAAAAAAHHFkQ+YGM86XznsBLd0AAAAAALiE0A0AAAAAgEsI3QAAAAAAuITQDQAAAACASwjdAAAAAAC4hNANAAAAALBGkj9JEv3eudCWd14JAAAAACCmJScky21/uE0CgYCZ9wJaugEAAAAAcAmhGwAAAAAAlxC6AQAAAABWKAwVyksrX5LXf3zdzHsB53QDAAAAAKwQckKydudaycnJMfNeQEs3AAAAAAAuIXQDAAAAAOASQjcAAAAAAC4hdAMAAAAA4BJCNwAAAAAALom70csdxzE/s7KyxGahUEiys7MlNTVV/H6OjdiG+tiPGtmN+tiPGtmN+tiN+tiPGtkrP5gveTl5krc3z2S2/KR8sVU4U4YzZll8zsHW8JhffvlFWrRoEe3dAAAAAAB4wKZNm6R58+Zl3h93oVuPav32229Su3Zt8fl8YvNREz04oAWsU6dOtHcHJVAf+1Eju1Ef+1Eju1Efu1Ef+1Eju2XFSH00SmuPiaZNm5bbYyLuupfrm1HeUQjb6IfM5g9avKM+9qNGdqM+9qNGdqM+dqM+9qNGdqsTA/WpW7fuQdfhBAYAAAAAAFxC6AYAAAAAwCWEbkulpKTInXfeaX7CPtTHftTIbtTHftTIbtTHbtTHftTIbikeq0/cDaQGAAAAAEB1oaUbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQuqvBokWLZMiQIeai6T6fT2bPnn3QxyxYsEC6d+9uBg9o06aNTJs27YB1HnvsMTnyyCMlNTVVTjzxRPniiy9cegXeV9kavfHGG3LmmWdKenq6uXZgr169ZM6cOcXWueuuu8y2Iqdjjz3W5VfiTZWtj35/Sr73Om3ZsqXYenyHolOfSy+9tNT6dOzYsWgdvj9VZ/z48XL88cdL7dq1JSMjQ4YNGyZr1qw56ONee+01857r96Nz587y7rvvFrtfh4S54447pEmTJlKjRg3p16+f/Pjjjy6+Eu86lBo99dRT8oc//EHq169vJn3/S/4OK+27NmDAAJdfjfccSn30/20l33v9LkXiOxTdGvXt27fUv0WDBw8uWofvUNWYMmWKdOnSpeia2/r/5vfeey+u/gYRuqtBTk6OdO3a1fwHvyLWrVtnvvCnnXaarFixQkaNGiVXXnllsVD3yiuvyOjRo82ofl999ZXZfv/+/SUQCLj4SryrsjXSkKGhW38BLFu2zNRKQ8fy5cuLrachYvPmzUXTJ5984tIr8LbK1idM/+BGvv/6hziM71D06jN58uRiddm0aZM0aNBAzj///GLr8f2pGgsXLpSRI0fKZ599JnPnzpWCggI566yzTN3KsnjxYhk+fLhcccUV5vea/gdWp1WrVhWt8+9//1sefvhheeKJJ+Tzzz+XtLQ08x3Kzc2tplcW3zXSg4tao48++kiWLFkiLVq0MI/59ddfi62nASHye/Tyyy9XwyvylkOpj9JwEfneb9iwodj9fIeiWyNtQImsj/5+S0hIOOBvEd+hw9e8eXO57777zP+Zly5dKqeffroMHTpUVq9eHT9/g3T0clQffctnzZpV7jo333yz07Fjx2LLLrzwQqd///5Ft0844QRn5MiRRbeDwaDTtGlTZ/z48S7sdXypSI1K06FDB2fs2LFFt++8806na9euVbx3qEh9PvroI7Perl27ylyH75A93x9d3+fzOevXry9axvfHPYFAwNRp4cKFZa5zwQUXOIMHDy627MQTT3T+93//18yHQiGncePGzoQJE4ruz8zMdFJSUpyXX37Zxb2PDxWpUUmFhYVO7dq1neeff75o2YgRI5yhQ4e6tJfxqyL1ee6555y6deuWeT/fIfu+Q5MmTTLfoT179hQt4zvknvr16ztPP/103PwNoqXbQnrEWrtIRNIjN7pc5efnmyNFkev4/X5zO7wOqlcoFJLs7GzTWhdJu7lol9ujjjpKLrroItm4cWPU9jEeHXfccabbkfZK+PTTT4uW8x2yyzPPPGPe+1atWhVbzvfHHbt37zY/S/6+qszfIe2RpadrRK5Tt25dc5oG36HqqVFJe/fuNa17JR+jLeLay6ddu3by17/+VXbs2FHl+xtvKlqfPXv2mN9r2guhZKse3yH7vkP6t+hPf/qTaTGNxHeoagWDQZkxY4bphaDdzOPlbxCh20L6IWrUqFGxZXo7KytL9u3bJ9u3bzcf2NLWKXnOKqrHxIkTzR/XCy64oGiZfvH1nK7333/fnMuivyD0/DsN53CXBm3tbvT666+bSf/Do+duaTdyxXfIHr/99ps5r0tPoYnE98e9A4R6ylKfPn2kU6dOlf47FP5+hH/yHYpejUq65ZZbzEGqyP+EarfYF154QebNmyf333+/6YI7cOBA8/sP7tZHA9qzzz4rb775pvznP/8xj+vdu7f88ssv5n6+Q3Z9h3Q8BO26XPJvEd+hqrNy5UqpVauWGa/qmmuukVmzZkmHDh3i5m9QYrR3AIh106dPl7Fjx5o/rJHnDOsv5TAdPEJDhB7xfvXVV805KnCP/mdHpzD9j85PP/0kkyZNkhdffDGq+4binn/+ealXr545VysS3x936DmP+h9Lzo/3Vo30XEltOdIWucjBurTVLkwHItLv0tFHH23WO+OMM6p83+NBReujLXiRrXj6d6h9+/by5JNPyrhx46phT+PXoXyHtJVbvyMnnHBCseV8h6pOu3btzFhV2gth5syZMmLECHMQo6zg7TW0dFuocePGsnXr1mLL9LYOyKGj8zVs2NAM9FDaOvpYVB/9T44eFdUgULIbTEkaLI455hhZu3Ztte0f/kv/kIbfe75DdtBTwLUl6OKLL5bk5ORy1+X7c/iuu+46efvtt83AWzqozaH8HQp/P8I/+Q5Fr0aRPa00dH/wwQcmEJRHT9XQ3398j6qvPmFJSUnSrVu3ovee75A9NdJuzvr/uYoc0OU7dOiSk5PNFZl69OhhRpvXAVh1YNV4+RtE6LaQHhnVbiyRdCTG8BFT/dDqBzZyHe1Ko7fLOjcCVU9Hr7zsssvMz8jLS5RFu59ra6t2fUb106Or4fee75Ad9Ai3/selIv/R4ftzeAc39D+i2pVv/vz50rp168P+O6Tb0P/YRK6jp0DpCLJ8h6qnRuHRe7XVVE/D6Nmz50HX167Nej4q36PqqU8k7Y6s3WvD7z3fIXtqpJemysvLk7/85S8HXZfvUNUJhULmfY+bv0HRHsktHmRnZzvLly83k77lDz74oJnfsGGDuf/WW291Lr744qL1f/75Z6dmzZrOTTfd5Hz33XfOY4895iQkJDjvv/9+0TozZswwI/RNmzbN+fbbb52rr77aqVevnrNly5aovMZ4q9FLL73kJCYmmtps3ry5aNKRE8NuuOEGZ8GCBc66deucTz/91OnXr5/TsGFDM6Im3K2PjkA6e/Zs58cff3RWrlzpXH/99Y7f73c+/PDDonX4DkWvPmF/+ctfzGikpeH7U3X++te/mlGU9f2M/H21d+/eonW0PlqnMH3P9XfcxIkTzd8hHU0+KSnJfJ/C7rvvPvOdefPNN51vvvnGjPDbunVrZ9++fdX+GuOxRvr+JycnOzNnziz2GP0+Kv154403OkuWLDHfI/391717d6dt27ZObm5uVF5nPNVHr2YyZ84c56effnKWLVvm/OlPf3JSU1Od1atXF63Ddyi6NQo7+eSTzVWCSuI7VHVuvfVWM5K8vo/6WdfbetWSDz74IG7+BhG6q0H48kUlJ70MgdKfp5566gGPOe6448wf1KOOOspceqKkRx55xGnZsqVZRy9/9Nlnn1Xba4r3Gul8eesr/QXepEkTU59mzZqZ22vXro3K64u3+tx///3O0Ucfbf6D06BBA6dv377O/PnzD9gu36Ho/Y7TA1Q1atRwpk6dWuo2+f5UndJqo1Pk3xWtT+TvL/Xqq686xxxzjKmBXsbynXfeKXa/XrLl9ttvdxo1amQOYJ1xxhnOmjVrqu11xXuNWrVqVepj9D+nSsPGWWed5aSnp5v/rOr6V111FQcWq6k+o0aNKvr7ot+RQYMGOV999VWx7fIdiv7vue+//96sFw5/kfgOVZ3LL7/cvH/6fdD3Uz/rke95PPwN8uk/0W5tBwAAAADAizinGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAPuv766+Xqq6+WUCgU7V0BACCuEboBAPCYTZs2Sbt27eTJJ58Uv58/9QAARJPPcRwnqnsAAAAAAIBHcfgbAACPuPTSS8Xn8x0wDRgwINq7BgBA3EqM9g4AAICqowH7ueeeK7YsJSUlavsDAEC8o6UbAAAP0YDduHHjYlP9+vXNfdrqPWXKFBk4cKDUqFFDjjrqKJk5c2axx69cuVJOP/10c/8RRxxhBmPbs2dPsXWeffZZ6dixo3muJk2ayHXXXVd034MPPiidO3eWtLQ0adGihVx77bUHPB4AgHhC6AYAII7cfvvtcu6558rXX38tF110kfzpT3+S7777ztyXk5Mj/fv3NyH9yy+/lNdee00+/PDDYqFaQ/vIkSNNGNeA/tZbb0mbNm2K7teB2x5++GFZvXq1PP/88zJ//ny5+eabo/JaAQCwAQOpAQDgoXO6//Of/0hqamqx5bfddpuZtKX7mmuuMcE57KSTTpLu3bvL448/Lk899ZTccsstZvRzbalW7777rgwZMkR+++03adSokTRr1kwuu+wy+de//lWhfdKWdH3O7du3V/GrBQAgNnBONwAAHnLaaacVC9WqQYMGRfO9evUqdp/eXrFihZnXFu+uXbsWBW7Vp08fc63vNWvWmNCu4fuMM84o8/m1ZXz8+PHy/fffS1ZWlhQWFkpubq7s3btXatasWYWvFACA2ED3cgAAPEQDs3b3jpwiQ/fh0PO8y7N+/Xo5++yzpUuXLvL666/LsmXL5LHHHjP35efnV8k+AAAQawjdAADEkc8+++yA2+3btzfz+lPP9dZzu8M+/fRTc552u3btpHbt2nLkkUfKvHnzSt22hmxtFX/ggQdMt/VjjjnGtIwDABDP6F4OAICH5OXlyZYtW4otS0xMlIYNG5p5HRytZ8+ecvLJJ8tLL70kX3zxhTzzzDPmPh1Y7c4775QRI0bIXXfdJdu2bZO//e1vcvHFF5vzuZUu13O0MzIyzCjo2dnZJpjretqqXlBQII888og5D1yXP/HEE1F4FwAAsAct3QAAeMj7779vLuMVOWnADhs7dqzMmDHDdAF/4YUX5OWXX5YOHTqY+/Sc6zlz5sjOnTvl+OOPl/POO8+cv/3oo48WPV4D+UMPPWQGXtPLhml38h9//NHcp+eD6yXD7r//funUqZMJ9Xp+NwAA8YzRywEAiBM6ENqsWbNk2LBh0d4VAADiBi3dAAAAAAC4hNANAAAAAIBLGEgNAIA4wRllAABUP1q6AQAAAABwCaEbAAAAAACXELoBAAAAAHAJoRsAAAAAAJcQugEAAAAAcAmhGwAAAAAAlxC6AQAAAABwCaEbAAAAAACXELoBAAAAABB3/H+3MNHO6OsSZQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejor val loss: 3.7960 en época 3\n"
     ]
    }
   ],
   "source": [
    "# Graficar pérdidas\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.plot(epochs_range, train_losses, 'b-', label='Train Loss')\n",
    "plt.plot(epochs_range, val_losses, 'r-', label='Val Loss')\n",
    "\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Curvas de Entrenamiento')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Marcar mejor época\n",
    "best_epoch = val_losses.index(min(val_losses)) + 1\n",
    "plt.axvline(x=best_epoch, color='g', linestyle='--', alpha=0.5, label=f'Mejor época: {best_epoch}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMejor val loss: {best_val_loss:.4f} en época {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generación de Ejemplo con Modelo Entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 10,000 Helldivers vs 1 Adeptus Custodes 10,000 Helldivers are working together to face off against one of the Emperor's Talons. Each Helldiver has a different loadout but they have all primaries, secondaries, and armor from Helldivers 2 equipped. The Custodian is wearing it's standard Auramite armor and equipped with a Guardian Spear with only 1 bolter magazine. Battle takes place in the Emperor's palace in Terra. All combatants are bloodlusted. R1: Helldivers don't have access to any Strategems. R2: Helldivers have access to all Strategems with regular cooldowns\n",
      "\n",
      "Respuesta generada:\n",
      "I don't think the Custodians have access to any Strategems with regular cooldowns. They have access to all Strategems with regular cooldowns.\n"
     ]
    }
   ],
   "source": [
    "# Cargar mejor modelo\n",
    "checkpoint = torch.load('prod/modelo.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Función de generación\n",
    "def generate_response(model, tokenizer, input_text, device, max_length=128):\n",
    "    \"\"\"Genera una respuesta para el input dado\"\"\"\n",
    "    # Tokenizar input\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors='pt',\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generar\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    # Decodificar\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Probar con un ejemplo\n",
    "test_input = \"10,000 Helldivers vs 1 Adeptus Custodes 10,000 Helldivers are working together to face off against one of the Emperor's Talons. Each Helldiver has a different loadout but they have all primaries, secondaries, and armor from Helldivers 2 equipped. The Custodian is wearing it's standard Auramite armor and equipped with a Guardian Spear with only 1 bolter magazine. Battle takes place in the Emperor's palace in Terra. All combatants are bloodlusted. R1: Helldivers don't have access to any Strategems. R2: Helldivers have access to all Strategems with regular cooldowns\"\n",
    "print(f\"Input: {test_input}\")\n",
    "print(f\"\\nRespuesta generada:\")\n",
    "response = generate_response(model, tokenizer, test_input, device)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar Información del Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar métricas y configuración\n",
    "training_info = {\n",
    "    'model_name': model_name,\n",
    "    'best_epoch': best_epoch,\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'final_train_loss': train_losses[-1],\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'hyperparameters': {\n",
    "        'epochs': EPOCHS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'gradient_accumulation_steps': GRADIENT_ACCUMULATION_STEPS,\n",
    "        'warmup_steps': WARMUP_STEPS,\n",
    "        'max_grad_norm': MAX_GRAD_NORM,\n",
    "        'weight_decay': WEIGHT_DECAY\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'train_size': len(train_df),\n",
    "        'val_size': len(val_df),\n",
    "        'max_input_length': MAX_INPUT_LENGTH,\n",
    "        'max_output_length': MAX_OUTPUT_LENGTH\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('training_info.pkl', 'wb') as f:\n",
    "    pickle.dump(training_info, f)\n",
    "\n",
    "print(\"\\nResumen del entrenamiento:\")\n",
    "print(f\"Modelo: {model_name}\")\n",
    "print(f\"Mejor época: {best_epoch}\")\n",
    "print(f\"Mejor val loss: {best_val_loss:.4f}\")\n",
    "print(f\"Tiempo total de entrenamiento: ~{len(train_losses) * (epoch_time/60):.1f} minutos\")\n",
    "print(f\"\\nModelo guardado en: prod/modelo.pth\")\n",
    "print(f\"Información guardada en: training_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del Entrenamiento\n",
    "\n",
    "- ✅ Modelo T5-small cargado y configurado\n",
    "- ✅ Optimizador AdamW con learning rate scheduling\n",
    "- ✅ Gradient accumulation implementado para memoria limitada\n",
    "- ✅ Early stopping para evitar overfitting\n",
    "- ✅ Modelo entrenado y guardado en `prod/modelo.pth`\n",
    "- ✅ Curvas de entrenamiento visualizadas\n",
    "- ✅ Generación de ejemplo funcional\n",
    "\n",
    "**Siguiente paso**: Evaluación exhaustiva del modelo en `model_evaluation.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
